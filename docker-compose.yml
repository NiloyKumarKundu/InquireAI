version: "3.8"

networks:
  llm_network:
    driver: bridge

services:
  app:
    build:
      context: ./LLM-Hub
    ports:
      - "8501:8501"
    depends_on:
      - ollama
    volumes:
      - ./LLM-Hub:/app
    environment:
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_PORT=8501
    networks:
      - llm_network

  ollama:
    image: ollama/ollama:latest # Use the official Ollama image, adjust the tag if necessary
    container_name: ollama
    ports:
      - "11435:11434" # Change port if needed
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./ollama:/root/.ollama
    networks:
      - llm_network
